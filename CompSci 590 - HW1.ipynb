{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CompSci 590-06: Elements of Deep Learning\n",
    "<br>Homework 1: Loss Function for Classification\n",
    "<br>Nick Carroll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Derivation of Cross Entropy Gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\ell_{CE}(\\boldsymbol{\\theta}) = -\\textbf{y}_{n}^{T}{\\textbf{s}_n} + log \\sum_{k} exp(s_{nk})$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\nabla_{\\textbf{s}_n} \\ell_{CE}  = \\nabla(-\\textbf{y}_{n}^{T}{\\textbf{s}_n} + log \\sum_{k} exp(s_{nk})) = -\\nabla(\\textbf{y}_{n}^{T}{\\textbf{s}_n}) + \\nabla(log \\sum_{k} exp(s_{nk})) = -\\textbf{y}_{n}^{T}{\\nabla(\\textbf{s}_n)} + \\frac{\\nabla(exp(s_{nk}))}{\\sum_{k} exp(s_{nk})} = -\\textbf{y}_{n}^{T}{\\nabla(\\textbf{s}_n)} + \\frac{exp(s_{nk})\\nabla(s_{nk})}{\\sum_{k} exp(s_{nk})} $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 The best validation accuracy calculated was 0.900."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Derivation of MSE Gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\ell_{MSE}(\\theta) = \\frac{1}{K}\\|{y_n - s_n}\\|_2^2 $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\nabla(\\ell_{MSE}( \\boldsymbol{\\theta})) = \\nabla(\\frac{1}{K}\\|{\\textbf{y}_n - \\textbf{s}_n}\\|_2^2) = \\frac{2}{K}\\nabla({\\textbf{y}_n - \\textbf{s}_n}) = \\frac{-2}{K}({\\textbf{y}_n - \\textbf{s}_n})\\nabla(\\textbf{s}_n) $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 The best validation accuracy calculated was 0.843."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Derivation of \"SoftMSE\" Gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\ell_{SoftMSE}(\\boldsymbol{\\theta}) = \\frac{1}{K}\\|\\textbf{y}_n - \\textbf{softmax}(\\textbf{s}_n)\\|_2^2 $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\textbf{softmax}(\\textbf{s}_n) = \\frac{exp(\\textbf{s}_n)}{\\sum_{k}exp(\\textbf{s}_n)} $,  $ log(\\textbf{softmax}(\\textbf{s}_n)) = \\textbf{s}_n - log(\\sum_{k}exp(\\textbf{s}_n)) $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\nabla(log(\\textbf{softmax}(\\textbf{s}_n))) = \\frac{\\nabla(\\textbf{softmax}(\\textbf{s}_n))}{\\textbf{softmax}(\\textbf{s}_n)} $, $ \\nabla(\\textbf{softmax}(\\textbf{s}_n)) = \\textbf{softmax}(\\textbf{s}_n)\\nabla(log(\\textbf{softmax}(\\textbf{s}_n))) $ , $ \\nabla(log(\\textbf{softmax})) = \\nabla(\\textbf{s}_n - log(\\sum_{k}exp(\\textbf{s}_n))) = \\nabla(\\textbf{s}_n) - \\nabla(log(\\sum_{k}exp(\\textbf{s}_n))) = \\nabla(\\textbf{s}_n) - \\frac{\\nabla(exp(\\textbf{s}_n))}{\\sum_{k}exp(\\textbf{s}_n)} = \\nabla(\\textbf{s}_n) - \\frac{exp(\\textbf{s}_n)\\nabla(\\textbf{s}_n)}{\\sum_{k}exp(\\textbf{s}_n)} = \\nabla(\\textbf{s}_n) - \\textbf{softmax}(\\textbf{s}_n)\\nabla(\\textbf{s}_n) $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\nabla(\\ell_{SoftMSE}(\\boldsymbol{\\theta})) = \\nabla(\\frac{1}{K}\\|\\textbf{y}_n - \\textbf{softmax}(\\textbf{s}_n)\\|_2^2) = \\frac{1}{K}\\nabla(\\|\\textbf{y}_n - \\textbf{softmax}(\\textbf{s}_n)\\|_2^2) = \\frac{2}{K}(\\textbf{y}_n - \\textbf{softmax}(\\textbf{s}_n))\\nabla(\\textbf{y}_n - \\textbf{softmax}(\\textbf{s}_n)) = \\frac{-2}{K}(\\textbf{y}_n - \\textbf{softmax}(\\textbf{s}_n))\\nabla(\\textbf{softmax}(\\textbf{s}_n)) = \\frac{-2}{K}(\\textbf{y}_n - \\textbf{softmax}(\\textbf{s}_n))\\textbf{softmax}(\\textbf{s}_n)(\\nabla(\\textbf{s}_n) - \\textbf{softmax}(\\textbf{s}_n)\\nabla(\\textbf{s}_n)) $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 The best validation accuracy calculated was 0.849."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Analyzing Gradients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial{\\ell}_{CE}}{\\partial{s}_{nk}} < 0 $ cannot occur where $ k \\neq y_n $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial{\\ell}_{MSE}}{\\partial{s}_{nk}} < 0 $ when $ s < 0 $ where $ k \\neq y_n $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial{\\ell}_{SoftMSE}}{\\partial{s}_{nk}} < 0 $ cannot occur where $ k \\neq y_n $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial{\\ell}_{CE}}{\\partial{s}_{nk}} < -1 $ cannot occur where $ k \\neq y_n $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial{\\ell}_{MSE}}{\\partial{s}_{nk}} < -1 $ when $ s < \\frac{k}{2} $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial{\\ell}_{SoftMSE}}{\\partial{s}_{nk}} < -1 $ cannot occur where $ k \\neq y_n $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 If the loss function is negative when k is not the correct label, the model will continue to optimize around the incorrect label, when it should be only optimizing on the correct labels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate loss function: $ \\ell_{\\sigma MSE}(\\boldsymbol{\\theta}) = \\frac{1}{K}\\|\\textbf{y}_n - \\textbf{sigmoid}(\\textbf{s}_n)\\|_2^2 $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\nabla(\\ell_{\\sigma MSE}(\\boldsymbol{\\theta})) = \\nabla(\\frac{1}{K}\\|\\textbf{y}_n - \\textbf{sigmoid}(\\textbf{s}_n)\\|_2^2) = \\frac{1}{K}\\nabla(\\|\\textbf{y}_n - \\textbf{sigmoid}(\\textbf{s}_n)\\|_2^2) = \\frac{2}{K}(\\textbf{y}_n - \\textbf{sigmoid}(\\textbf{s}_n))\\nabla(\\textbf{y}_n - \\textbf{sigmoid}(\\textbf{s}_n)) = \\frac{-2}{K}(\\textbf{y}_n - \\textbf{sigmoid}(\\textbf{s}_n))\\nabla(\\textbf{sigmoid}(\\textbf{s}_n)) = \\frac{-2}{K}(\\textbf{y}_n - \\textbf{sigmoid}(\\textbf{s}_n))(1 - \\textbf{sigmoid}(\\textbf{s}_n))\\nabla(\\textbf{s}_n) $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 The best validation accuracy calculated was 0.871."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I affirm that I have followed the instructions for this assignment and that my answers and submitted code represent my own work, without the use of any unpermitted aids or resources.  Nick Carroll"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72db1ef4dcd6e2344e9289c13171ece59739274764f83c0b8f73f911c07b82ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
